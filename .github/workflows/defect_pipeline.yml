name: Pipeline for model training, evaluation and inference

on:
  push:
    branches: [main,feature/*]
  workflow_dispatch:

jobs:
  setup-env:
    name:  Setup Python Virtual Environment
    runs-on: [self-hosted, self-hosted] # Use the label you assigned to your runner
    
    outputs:
      venv_path: ${{ steps.set-path.outputs.venv }}

    steps:
      - name:  Checkout repository
        uses: actions/checkout@v4

      - name:  create virtual environment and install packages
        id: set-path
        run: |
          VENV_PATH="$HOME/Documents/.venv" # Or any other path on your local machine
          mkdir -p "$(dirname "$VENV_PATH")"
          echo "venv=$VENV_PATH" >> $GITHUB_OUTPUT

          # Using standard venv and pip. If you have uv installed and prefer it,
          # you can revert these lines to use uv venv and uv pip install.
          python3 -m venv "$VENV_PATH"
          source "$VENV_PATH/bin/activate"
          pip install --upgrade pip
          pip install -r requirements.txt
        shell: /bin/bash -e {0}

  runTrainEvaluationModel:
    name:  Run Train Model and evaluation Pipeline stage
    runs-on: [self-hosted, self-hosted] # Use the label you assigned to your runner
    needs: setup-env
    
    steps:
      - name:  Checkout repository
        uses: actions/checkout@v4

      - name: ▶️ Run  pipeline step for model Trains and Evaluation
        env:
            # Point to your local MLflow server
            MLFLOW_TRACKING_URI: http://localhost:5000
            PYTHONUNBUFFERED: 1
            MLFLOW_EXPERIMENT_NAME: Defect Detection Experiment # You can hardcode or use a GitHub variable here

        run: |
           VENV_PATH="${{ needs.setup-env.outputs.venv_path }}"
           if [ ! -d "$VENV_PATH" ]; then
             echo "❌ Venv not found at $VENV_PATH"
             exit 1
           fi
           source "$VENV_PATH/bin/activate"
           echo "Model Train execution starts.... " 
           python training/train.py # Assuming your train script is training/train.py based on folder structure
           echo "Model Evaluation execution starts.... " 
           python evaluation/evaluate.py # Assuming your evaluate script is evaluation/evaluate.py
           echo "Model Evaluation completed.... "  
          
        shell: /bin/bash -e {0}
        working-directory: ${{ github.workspace }} 
      
      - name:  Upload trained model artifact
        if: github.ref == 'refs/heads/main'
        uses: actions/upload-artifact@v4
        with:
          name: casting_model_h5
          path: models/ # Adjust if your model output path is different

  
  runInferenceStage:
    name:  Run Inference Pipeline stage
    runs-on: [self-hosted, self-hosted] # Use the label you assigned to your runner
    needs: 
      - setup-env
      - runTrainEvaluationModel
   
    steps:
      - name:  Checkout repository
        uses: actions/checkout@v4

      - name: ▶️ Run  pipeline step for  inference check
        env:
            # Point to your local MLflow server
            MLFLOW_TRACKING_URI: http://localhost:5000
            PYTHONUNBUFFERED: 1
            MLFLOW_EXPERIMENT_NAME: Defect Detection Experiment # Consistent with training/evaluation

        run: |
           VENV_PATH="${{ needs.setup-env.outputs.venv_path }}"
           if [ ! -d "$VENV_PATH" ]; then
             echo "❌ Venv not found at $VENV_PATH"
             exit 1
           fi
           source "$VENV_PATH/bin/activate"
           echo "Model Inference execution starts.... " 
           python inference/infer.py # Assuming your infer script is inference/infer.py
        shell: /bin/bash -e {0}
        working-directory: ${{ github.workspace }}