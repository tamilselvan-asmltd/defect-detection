name: Defect Detection Pipeline (Local MLflow)

on:
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  setup-and-preprocess:
    runs-on: self-hosted

    steps:
    - name: Checkout repo
      uses: actions/checkout@v3

    - name: Setup Python and install dependencies
      run: |
        python3 -m venv .venv
        . .venv/bin/activate
        python -m pip install --upgrade pip
        pip install mlflow==2.12.1 protobuf==3.20.3
        pip install -r requirements.txt
      shell: bash

    - name: Start MLflow Tracking Server
      run: |
        . .venv/bin/activate
        nohup mlflow server \
          --backend-store-uri sqlite:///mlruns.db \
          --default-artifact-root $(pwd)/mlruns \
          --host 127.0.0.1 --port 5000 > mlflow.log 2>&1 &
        for i in {1..15}; do curl -s http://127.0.0.1:5000 && break || sleep 1; done
      shell: bash

    - name: Preprocess Data
      run: |
        . .venv/bin/activate
        python preprocess/preprocess.py --config preprocess/config.yaml
      shell: bash

  train:
    runs-on: self-hosted
    needs: setup-and-preprocess

    steps:
    - name: Checkout repo
      uses: actions/checkout@v3

    - name: Setup Python and install dependencies
      run: |
        python3 -m venv .venv
        . .venv/bin/activate
        python -m pip install --upgrade pip
        pip install mlflow==2.12.1 protobuf==3.20.3
        pip install -r requirements.txt
      shell: bash

    - name: Train model
      run: |
        . .venv/bin/activate
        python training/train.py --config training/config.yaml --mlflow_config mlflow_config.yaml
      shell: bash

  evaluate:
    runs-on: self-hosted
    needs: train

    steps:
    - name: Checkout repo
      uses: actions/checkout@v3

    - name: Setup Python and install dependencies
      run: |
        python3 -m venv .venv
        . .venv/bin/activate
        python -m pip install --upgrade pip
        pip install mlflow==2.12.1 protobuf==3.20.3
        pip install -r requirements.txt
      shell: bash

    - name: Evaluate model
      run: |
        . .venv/bin/activate
        python evaluation/evaluate.py --config evaluation/config.yaml --mlflow_config mlflow_config.yaml
      shell: bash

  deploy:
    runs-on: self-hosted
    needs: evaluate

    steps:
    - name: Checkout repo
      uses: actions/checkout@v3

    - name: Setup Python and install dependencies
      run: |
        python3 -m venv .venv
        . .venv/bin/activate
        python -m pip install --upgrade pip
        pip install mlflow==2.12.1 protobuf==3.20.3
        pip install -r requirements.txt
      shell: bash

    - name: Deploy model (prod alias)
      run: |
        echo "Handled in evaluation/evaluate.py"
      shell: bash

  inference:
    runs-on: self-hosted
    needs: deploy

    steps:
    - name: Checkout repo
      uses: actions/checkout@v3

    - name: Setup Python and install dependencies
      run: |
        python3 -m venv .venv
        . .venv/bin/activate
        python -m pip install --upgrade pip
        pip install mlflow==2.12.1 protobuf==3.20.3
        pip install -r requirements.txt
      shell: bash

    - name: Run Inference
      run: |
        . .venv/bin/activate
        DUMMY_IMAGE_PATH="data/test/ok_front/cast_ok_0_10.jpeg"
        if [ -f "$DUMMY_IMAGE_PATH" ]; then
          python inference/infer.py --config inference/config.yaml --mlflow_config mlflow_config.yaml --image_path "$DUMMY_IMAGE_PATH"
        else
          echo "Dummy image not found. Skipping inference."
        fi
      shell: bash
