name: Defect Detection Pipeline (with MLflow UI)

on:
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  mlflow-server:
    runs-on: self-hosted
    steps:
    - name: Checkout repo
      uses: actions/checkout@v3

    - name: Set up Python and Start MLflow Tracking Server
      run: |
        python3 -m venv venv
        source venv/bin/activate
        pip install --upgrade pip
        pip install mlflow==2.12.1 protobuf==3.20.3
        nohup mlflow server \
          --host 0.0.0.0 \
          --port 5000 \
          --backend-store-uri sqlite:///mlruns.db \
          --default-artifact-root ./mlruns > mlflow_server.log 2>&1 &
        # Wait for MLflow server to come up
        for i in {1..15}; do curl -s http://127.0.0.1:5000 && break || sleep 1; done
      shell: bash

  preprocess:
    runs-on: self-hosted
    needs: mlflow-server
    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      run: |
        python3 -m venv venv
        source venv/bin/activate
        pip install --upgrade pip
        pip install -r requirements.txt
      shell: bash

    - name: Preprocess
      run: |
        source venv/bin/activate
        python preprocess/preprocess.py --config preprocess/config.yaml
      shell: bash

  train:
    runs-on: self-hosted
    needs: preprocess
    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      run: |
        python3 -m venv venv
        source venv/bin/activate
        pip install -r requirements.txt
      shell: bash

    - name: Train
      run: |
        source venv/bin/activate
        python training/train.py --config training/config.yaml --mlflow_config mlflow_config.yaml
      shell: bash

  evaluate:
    runs-on: self-hosted
    needs: train
    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      run: |
        python3 -m venv venv
        source venv/bin/activate
        pip install -r requirements.txt
      shell: bash

    - name: Evaluate
      run: |
        source venv/bin/activate
        python evaluation/evaluate.py --config evaluation/config.yaml --mlflow_config mlflow_config.yaml
      shell: bash

  deploy:
    runs-on: self-hosted
    needs: evaluate
    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      run: |
        python3 -m venv venv
        source venv/bin/activate
        pip install -r requirements.txt
      shell: bash

    - name: Deploy
      run: |
        echo "Handled inside evaluation/evaluate.py"
      shell: bash

  inference:
    runs-on: self-hosted
    needs: deploy
    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      run: |
        python3 -m venv venv
        source venv/bin/activate
        pip install -r requirements.txt
      shell: bash

    - name: Run Inference
      run: |
        source venv/bin/activate
        DUMMY_IMAGE_PATH="data/test/ok_front/cast_ok_0_10.jpeg"
        if [ -f "$DUMMY_IMAGE_PATH" ]; then
          python inference/infer.py --config inference/config.yaml --mlflow_config mlflow_config.yaml --image_path "$DUMMY_IMAGE_PATH"
        else
          echo "Dummy image not found. Skipping inference."
        fi
      shell: bash
